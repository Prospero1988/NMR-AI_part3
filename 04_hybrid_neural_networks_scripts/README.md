# ğŸ§ª NMR-based logD Prediction using Deep Learning

This repository contains three deep learning models for predicting the CHI logD property from **Â¹H and Â¹Â³C NMR spectra**. The models differ in architecture and input representation strategies, allowing for benchmarking and analysis of different fusion techniques for spectral data.

---

## ğŸ“Œ Key Features

- Predicts **CHI logD** using **1D NMR spectra** (Â¹H + Â¹Â³C)
- Supports three architectures: **MLP Dual-Stream**, **CNN Dual-Channel**, and **CNN Stacked-Spectra**
- Full integration with **Optuna** for hyperparameter optimization and **MLflow** for experiment tracking
- Robust evaluation using **3-fold CV** during optimization and **10-fold CV** during final model assessment
- Automatically logs metrics, predictions, plots, and models
- Compatible with both **CPU and CUDA-enabled GPUs**

---

## ğŸ§  Model Architectures

| Script                             | Architecture               | Input Shape             | Description                                                                 |
|-----------------------------------|----------------------------|--------------------------|-----------------------------------------------------------------------------|
| `mlp_dualstream_1H_13C.py`        | **MLP Dual-Stream**        | `(B, 2, 200)`            | Two separate MLP branches for Â¹H and Â¹Â³C, merged into a shared embedding    |
| `cnn_2d_dualchannel_1H_13C.py`    | **CNN 2D Dual-Channel**    | `(B, 2, 1, 200)`         | Treats Â¹H and Â¹Â³C as separate channels, similar to RGB image channels       |
| `cnn_2d_stacked_1H_13C.py`        | **CNN 2D Stacked-Spectra** | `(B, 1, 2, 200)`         | Combines Â¹H and Â¹Â³C vertically as a 2Ã—200 image, processed spatially        |

> All architectures output a single predicted scalar per sample (`logD`) and include regularization layers (Dropout, BatchNorm) and optional non-linearities (e.g., SiLU).

---

## ğŸ“‚ Input Data Format

Each model takes two CSV files as input:

- `--path_1h` â†’ CSV file with Â¹H NMR spectrum (200 features)
- `--path_13c` â†’ CSV file with Â¹Â³C NMR spectrum (200 features)

Each file must have the following format:
```
MOLECULE_NAME,LABEL,f_0,f_1,...,f_199
```
- `MOLECULE_NAME`: Unique ID of the molecule
- `LABEL`: Target value (CHI logD)
- `f_0` to `f_199`: Intensity values of the NMR spectrum

---

## ğŸš€ How to Run

Each script can be run independently with the same CLI interface.

Example (MLP Dual-Stream):
```bash
python mlp_dualstream_1H_13C.py \
  --path_1h data/1H.csv \
  --path_13c data/13C.csv \
  --experiment_name MLP_Dual_Experiment \
  --n_trials 50 \
  --epochs_10cv 100
```

Replace the script name to run the CNN variants:
- `cnn_2d_dualchannel_1H_13C.py`
- `cnn_2d_stacked_1H_13C.py`

---

## âš™ï¸ Dependencies

You can install the required packages via `pip`:

```bash
pip install torch optuna mlflow pandas matplotlib scikit-learn
```

For CUDA support, ensure your environment has the correct PyTorch version with GPU support:
https://pytorch.org/get-started/locally/

---

## ğŸ§ª Training & Evaluation Workflow

Each run includes the following stages:

1. **Data Loading**: Reads and merges Â¹H and Â¹Â³C spectra
2. **Optimization**: Optuna performs hyperparameter search using 3-fold CV
3. **Final Evaluation**: Best model is retrained and evaluated using 10-fold CV
4. **MLflow Logging**:
   - All parameters, metrics, and artifacts
   - RMSE, MAE, RÂ², Pearson metrics
   - Trial history and parameter importance plots
   - Predicted vs true values and error scatterplots

Final model is trained on the full dataset with early stopping and logged as an MLflow artifact.

---

## ğŸ“Š Evaluation Metrics

For every model, the following are calculated:

- **RMSE** (Root Mean Square Error)
- **MAE** (Mean Absolute Error)
- **RÂ²** (Coefficient of Determination)
- **Pearson Correlation Coefficient**

These are logged with means and standard deviations across CV folds.

---

## ğŸ“ Output Directory Structure

Each script creates a result directory based on the input file name and model type:

```
<DATASET>-results-<model_type>/
â”œâ”€â”€ optuna_trials_*.csv
â”œâ”€â”€ metrics_*.csv
â”œâ”€â”€ cv_predictions_*.csv
â”œâ”€â”€ real_vs_pred_plot_*.png
â”œâ”€â”€ error_plot_*.png
â”œâ”€â”€ param_importances_*.json/png
â””â”€â”€ model_<type>/ (MLflow model)
```

---

## ğŸ” Model Comparison

| Architecture        | Separation Strategy    | Complexity | Best Forâ€¦                        |
|---------------------|------------------------|------------|----------------------------------|
| MLP Dual-Stream     | Parallel, learned merge | â˜…â˜…â˜…â˜†â˜†      | Clear separation of Â¹H / Â¹Â³C     |
| CNN Dual-Channel    | Channel-based fusion   | â˜…â˜…â˜…â˜…â˜†      | Learning local spatial patterns  |
| CNN Stacked-Spectra | Spatial stacking       | â˜…â˜…â˜…â˜…â˜†      | Capturing cross-signal features |

---

## ğŸ§© Extension Ideas

- Add third input: **molecular fingerprints (e.g. ECFP4)**
- Switch to **multi-task regression** (e.g., predict multiple ADME properties)
- Use **attention-based architectures** to weigh Â¹H/Â¹Â³C contribution dynamically
- Implement **residual connections** or **Transformer-based NMR models**

---

## ğŸ’¬ Credits & Author

Developed by **Arek**, chemist and NMR specialist  
Architecture design and optimization powered by **PyTorch + Optuna + MLflow**

---

> *â€œThe spectra don't lie â€” they whisper secrets of solubility if you learn to listen.â€*
